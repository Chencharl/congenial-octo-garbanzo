import os
import pickle
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, random_split
from torch.optim.lr_scheduler import CosineAnnealingLR
from PIL import Image
from torchsummary import summary

# 加载元数据（标签）
    meta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))
    label_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]
    
    # 加载训练数据
    train_data = []
    train_labels = []
    for i in range(1, 6):
        batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))
        train_data.append(batch[b'data'])
        train_labels += batch[b'labels']
    
    # 拼接并转换为 HWC 格式
    train_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)
    train_labels = np.array(train_labels)
    
    # 定义训练数据的 transform（带数据增强）
    train_transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.ColorJitter(brightness=0.1, contrast=0.1),
        transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),
        transforms.RandomErasing(p=0.1, scale=(0.02, 0.08), value=0)
    ])
    
    # 定义测试数据的 transform（不使用随机增强，只做必要转换）
    test_transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))
    ])
    
    # 构建训练集（应用 train_transform）
    train_dataset = [(train_transform(img), label) for img, label in zip(train_data, train_labels)]
    # 划分训练集和验证集
    train_size = int(0.9 * len(train_dataset))
    val_size = len(train_dataset) - train_size
    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])
    
    # 加载测试集
    test_batch = load_cifar_batch(cifar_test_path)
    raw_data = test_batch[b'data']
    # 假设 raw_data 已经是 (10000, 32, 32, 3) 的 HWC 格式
    test_images = raw_data.astype(np.uint8)
    # 构建测试集（应用 test_transform）
    test_dataset = [test_transform(img) for img in test_images]
    
    # 创建 DataLoader
    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)
    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)
    # 定义训练模型函数
    def train_model(model, train_loader, val_loader, epochs=100):
        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
        optimizer = optim.AdamW(model.parameters(), lr=0.003, weight_decay=5e-5)
        scheduler = CosineAnnealingLR(optimizer, T_max=epochs)
    
        for epoch in range(epochs):
            model.train()
            running_loss = 0.0
            for images, labels in train_loader:
                images, labels = images.to(device), labels.to(device)
                optimizer.zero_grad()
                outputs = model(images)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                running_loss += loss.item()
    
            # 验证阶段
            model.eval()
            correct = 0
            total = 0
            with torch.no_grad():
                for images, labels in val_loader:
                    images, labels = images.to(device), labels.to(device)
                    outputs = model(images)
                    _, predicted = torch.max(outputs, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()
    
            scheduler.step()
            print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, '
                  f'Validation Accuracy: {100 * correct / total:.2f}%')
    
    # 定义自定义 ResNet 模型
    class ResidualBlock(nn.Module):
        def __init__(self, in_channels, out_channels, stride=1):
            super(ResidualBlock, self).__init__()
            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)
            self.bn1 = nn.BatchNorm2d(out_channels)
            self.relu = nn.ReLU(inplace=True)
            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)
            self.bn2 = nn.BatchNorm2d(out_channels)
            self.skip = nn.Sequential()
            if stride != 1 or in_channels != out_channels:
                self.skip = nn.Sequential(
                    nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),
                    nn.BatchNorm2d(out_channels)
                )
            self.dropout = nn.Dropout(0.3)
    
        def forward(self, x):
            identity = x
            if self.skip:
                identity = self.skip(x)
            out = self.conv1(x)
            out = self.bn1(out)
            out = self.relu(out)
            out = self.conv2(out)
            out = self.bn2(out)
            out += identity
            out = self.relu(out)
            out = self.dropout(out)
            return out
    
    class CustomResNet(nn.Module):
        def __init__(self, num_classes=10):
            super(CustomResNet, self).__init__()
            self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
            self.init_bn = nn.BatchNorm2d(64)
            self.relu = nn.ReLU(inplace=True)
            self.layer1 = ResidualBlock(64, 128, stride=1)
            self.layer2 = ResidualBlock(128, 256, stride=2)
            self.layer3 = ResidualBlock(256, 512, stride=2)
            self.avg_pool = nn.AdaptiveAvgPool2d(1)
            self.fc = nn.Linear(512, num_classes)
    
        def forward(self, x):
            out = self.init_conv(x)
            out = self.init_bn(out)
            out = self.relu(out)
            out = self.layer1(out)
            out = self.layer2(out)
            out = self.layer3(out)
            out = self.avg_pool(out)
            out = torch.flatten(out, 1)
            out = self.fc(out)
            return out
    
    # 创建模型并输出模型结构和参数总量
    model = CustomResNet().to(device)
    summary(model, (3, 32, 32))
    
    # 训练模型
    train_model(model, train_loader, val_loader, epochs=100)
    
    # 计算测试集的预测结果
    model.eval()
    predictions = []
    with torch.no_grad():
        for images in test_loader:
            images = images.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            predictions.extend(predicted.cpu().numpy())
    
    # 生成提交文件
    submission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})
    submission.to_csv('./submission.csv', index=False)
    print("✅ 提交文件已保存：./submission.csv")
